#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

ì—¬ëŸ¬ ì§€ì—­ì˜ ìƒê°€ì—…ì†Œ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘â†’ì „ì²˜ë¦¬â†’DBì €ì¥ê¹Œì§€ ì¼ê´„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
ì§€ì—­ ëª©ë¡ì€ APIë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ë¯€ë¡œ, í•˜ë“œì½”ë”© ì—†ì´ ì „êµ­ ì–´ë””ë“  ìˆ˜ì§‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python batch_collect.py                      # ì„œìš¸ì‹œ ì „ì²´ ìë™ ìˆ˜ì§‘
    python batch_collect.py --sido ë¶€ì‚°ê´‘ì—­ì‹œ    # ë¶€ì‚°ì‹œ ì „ì²´ ìë™ ìˆ˜ì§‘
    python batch_collect.py --force              # ê¸°ì¡´ ë°ì´í„° ë®ì–´ì“°ê¸°
    python batch_collect.py --skip-existing      # ì´ë¯¸ ìˆ˜ì§‘ëœ êµ¬ ìŠ¤í‚µ
"""

import asyncio
import argparse
from datetime import datetime
from typing import List, Tuple, Dict
from src.collector import Collector
from src.clients import DistrictClient
from src.storage import DataStorage
from src.preprocessor import DataPreprocessor
from src.database import DatabaseManager
from config.logging import logger


# ============================================================
# ì§€ì—­ ëª©ë¡ API ì¡°íšŒ í•¨ìˆ˜
# ============================================================


async def get_all_sido_list() -> List[Dict[str, str]]:
    """ì „êµ­ ì‹œë„ ëª©ë¡ì„ APIë¡œ ì¡°íšŒ

    Returns:
        ì‹œë„ ëª©ë¡ ë¦¬ìŠ¤íŠ¸ [{"ctprvnCd": "11", "ctprvnNm": "ì„œìš¸íŠ¹ë³„ì‹œ"}, ...]
    """
    logger.info("ğŸ“¡ APIë¡œ ì „êµ­ ì‹œë„ ëª©ë¡ ì¡°íšŒ ì¤‘...")

    async with DistrictClient() as client:
        response = await client.get_districtList(catId="mega")
        body = response.get("body", {})
        items = body.get("items", [])

    logger.success(f"âœ… ì‹œë„ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(items)} ê°œ")
    for item in items:
        logger.debug(f"  - {item.get('ctprvnNm')} ({item.get('ctprvnCd')})")

    return items


async def get_districts_from_api(sido_name: str) -> List[str]:
    """APIë¥¼ í†µí•´ íŠ¹ì • ì‹œë„ì˜ ì‹œêµ°êµ¬ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ì¡°íšŒ

    Args:
        sido_name: ì‹œë„ëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ")

    Returns:
        ì‹œêµ°êµ¬ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", ...])
    """
    logger.info(f"ğŸ“¡ APIë¡œ {sido_name} ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘...")

    try:
        async with DistrictClient() as client:
            # 1. ì‹œë„ ì½”ë“œ ì¡°íšŒ
            sido_response = await client.get_districtList(catId="mega")
            sido_items = sido_response.get("body", {}).get("items", [])

            sido_code = None
            for item in sido_items:
                if item.get("ctprvnNm") == sido_name:
                    sido_code = item.get("ctprvnCd")
                    break

            if not sido_code:
                raise ValueError(f"ì‹œë„ '{sido_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            logger.debug(f"ì‹œë„ ì½”ë“œ: {sido_code}")

            # 2. ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ
            sigungu_response = await client.get_districtList(
                catId="cty", parents_Cd=sido_code
            )
            sigungu_items = sigungu_response.get("body", {}).get("items", [])

            # 3. ì‹œêµ°êµ¬ëª…ë§Œ ì¶”ì¶œ
            district_names = [item.get("signguNm") for item in sigungu_items]

            logger.success(
                f"âœ… {sido_name} ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(district_names)} ê°œ"
            )
            for name in district_names:
                logger.debug(f"  - {name}")

            return district_names

    except Exception as e:
        logger.error(f"ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise


# ============================================================
# ë°°ì¹˜ ìˆ˜ì§‘ í•¨ìˆ˜
# ============================================================


async def collect_one_district(
    sido: str, sigungu: str, force_update: bool = False
) -> Tuple[bool, int, Dict[str, float]]:
    """í•œ ê°œ êµ¬ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘â†’ì „ì²˜ë¦¬â†’DBì €ì¥

    Args:
        sido: ì‹œë„ëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ")
        sigungu: ì‹œêµ°êµ¬ëª… (ì˜ˆ: "ê°•ë‚¨êµ¬")
        force_update: Trueë©´ ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ì¬ìˆ˜ì§‘

    Returns:
        (ì„±ê³µ ì—¬ë¶€, ì €ì¥ëœ ë ˆì½”ë“œ ìˆ˜, ì‹œê°„ í†µê³„)
        ì‹œê°„ í†µê³„: {"collect": ì´ˆ, "preprocess": ì´ˆ, "db_save": ì´ˆ, "total": ì´ˆ}
    """
    # ì „ì²´ ì‹œì‘ ì‹œê°„
    total_start = datetime.now()
    time_stats = {"collect": 0.0, "preprocess": 0.0, "db_save": 0.0, "total": 0.0}

    try:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ™ï¸  ì²˜ë¦¬ ì‹œì‘: {sido} {sigungu}")
        logger.info(f"{'='*60}")

        storage = DataStorage()
        preprocessor = DataPreprocessor()

        # ----------------------------------------
        # 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ (API í˜¸ì¶œ)
        # ----------------------------------------
        logger.info(f"\n[1/3] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        collect_start = datetime.now()

        # ê¸°ì¡´ íŒŒì¼ í™•ì¸
        if not force_update and storage.file_exists(sido, sigungu):
            logger.info(f"âœ… ê¸°ì¡´ Raw ë°ì´í„° íŒŒì¼ ì‚¬ìš©")
            df_raw = storage.load_stores(sido, sigungu)
        else:
            logger.info(f"ğŸŒ API í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘")
            async with Collector() as collector:
                df_raw = await collector.collect_stores(sido, sigungu)

            if not df_raw.empty:
                storage.save_stores(df_raw, sido, sigungu, format="parquet")
                logger.success(f"âœ… Raw ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(df_raw):,} ê±´")
            else:
                logger.warning(f"âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")
                return (False, 0, time_stats)

        collect_end = datetime.now()
        time_stats["collect"] = (collect_end - collect_start).total_seconds()
        logger.info(f"â±ï¸  ìˆ˜ì§‘ ì†Œìš” ì‹œê°„: {time_stats['collect']:.2f}ì´ˆ")

        # ----------------------------------------
        # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
        # ----------------------------------------
        logger.info(f"\n[2/3] ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        preprocess_start = datetime.now()

        df_processed = preprocessor.preprocess(df_raw)

        if df_processed.empty:
            logger.warning(f"âš ï¸ ì „ì²˜ë¦¬ í›„ ë°ì´í„° ì—†ìŒ")
            return (False, 0, time_stats)

        # ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥
        preprocessor.save_processed(df_processed, sido, sigungu)

        preprocess_end = datetime.now()
        time_stats["preprocess"] = (preprocess_end - preprocess_start).total_seconds()

        logger.success(
            f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df_raw):,} â†’ {len(df_processed):,} ê±´ "
            f"(ì œê±°: {len(df_raw) - len(df_processed):,})"
        )
        logger.info(f"â±ï¸  ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {time_stats['preprocess']:.2f}ì´ˆ")

        # ----------------------------------------
        # 3ë‹¨ê³„: PostgreSQL DBì— ì €ì¥
        # ----------------------------------------
        logger.info(f"\n[3/3] PostgreSQLì— ì €ì¥ ì¤‘...")
        db_start = datetime.now()

        with DatabaseManager() as db:
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            table_exists = db.table_exists("stores")

            if not table_exists:
                # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
                logger.info("ğŸ“¦ stores í…Œì´ë¸” ìƒì„± ì¤‘...")
                db.create_table_from_metadata(df=df_processed)
                db.create_indexes()
                logger.success("âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

            # ê¸°ì¡´ ë°ì´í„° í™•ì¸ ë° ì²˜ë¦¬
            existing_count = db.get_region_data_count(sido, sigungu)

            if existing_count > 0:
                if force_update:
                    logger.info(f"ğŸ”„ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘: {existing_count:,} ê±´")
                    db.delete_region_data(sido, sigungu)
                else:
                    logger.warning(
                        f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ì¡´ì¬: {existing_count:,} ê±´ "
                        f"(--force ì˜µì…˜ìœ¼ë¡œ ë®ì–´ì“°ê¸° ê°€ëŠ¥)"
                    )
                    return (False, existing_count, time_stats)

            # ë°ì´í„° ì‚½ì…
            inserted_count = db.insert_dataframe(df_processed, if_exists="append")

        db_end = datetime.now()
        time_stats["db_save"] = (db_end - db_start).total_seconds()

        logger.success(f"âœ… DB ì €ì¥ ì™„ë£Œ: {inserted_count:,} ê±´")
        logger.info(f"â±ï¸  DB ì €ì¥ ì†Œìš” ì‹œê°„: {time_stats['db_save']:.2f}ì´ˆ")

        # ì „ì²´ ì‹œê°„ ê³„ì‚°
        total_end = datetime.now()
        time_stats["total"] = (total_end - total_start).total_seconds()

        logger.success(f"\nâœ… {sido} {sigungu} ì²˜ë¦¬ ì™„ë£Œ!")
        logger.info(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {time_stats['total']:.2f}ì´ˆ")

        return (True, inserted_count, time_stats)

    except Exception as e:
        logger.error(f"\nâŒ {sido} {sigungu} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        logger.exception("ìƒì„¸ ì—ëŸ¬:")

        # ì‹¤íŒ¨í•´ë„ ì§€ê¸ˆê¹Œì§€ì˜ ì‹œê°„ì€ ê¸°ë¡
        total_end = datetime.now()
        time_stats["total"] = (total_end - total_start).total_seconds()

        return (False, 0, time_stats)


async def batch_collect(
    sido: str = "ì„œìš¸íŠ¹ë³„ì‹œ",
    districts: List[str] = None,
    force_update: bool = False,
    skip_existing: bool = False,
) -> None:
    """ì—¬ëŸ¬ ì§€ì—­ì˜ ë°ì´í„°ë¥¼ ì¼ê´„ ìˆ˜ì§‘

    Args:
        sido: ì‹œë„ëª… (ê¸°ë³¸ê°’: "ì„œìš¸íŠ¹ë³„ì‹œ")
        districts: ìˆ˜ì§‘í•  ì‹œêµ°êµ¬ ëª©ë¡ (Noneì´ë©´ APIë¡œ ìë™ ì¡°íšŒ)
        force_update: Trueë©´ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë®ì–´ì“°ê¸°
        skip_existing: Trueë©´ ì´ë¯¸ DBì— ìˆëŠ” ì§€ì—­ì€ ìŠ¤í‚µ
    """
    # districtsê°€ Noneì´ë©´ APIë¡œ ì¡°íšŒ
    if districts is None:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” {sido} ì‹œêµ°êµ¬ ëª©ë¡ì„ APIì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤...")
        logger.info(f"{'='*60}")
        districts = await get_districts_from_api(sido)

    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸš€ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘")
    logger.info(f"{'='*60}")
    logger.info(f"ëŒ€ìƒ ì§€ì—­: {sido}")
    logger.info(f"ìˆ˜ì§‘ êµ¬ ìˆ˜: {len(districts)} ê°œ")
    logger.info(f"ì˜µì…˜: force_update={force_update}, skip_existing={skip_existing}")
    logger.info(f"ì‹œì‘ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{'='*60}\n")

    # í†µê³„ ì´ˆê¸°í™”
    success_count = 0
    fail_count = 0
    skip_count = 0
    total_records = 0

    # ì‹œê°„ í†µê³„ ìˆ˜ì§‘ìš©
    all_time_stats = []  # ê° êµ¬ë³„ ì‹œê°„ í†µê³„
    district_times = []  # ê° êµ¬ë³„ (êµ¬ëª…, ì´ ì†Œìš”ì‹œê°„)

    start_time = datetime.now()

    # ê° êµ¬ë³„ë¡œ ìˆ˜ì§‘
    for i, sigungu in enumerate(districts, 1):
        logger.info(f"\n\nğŸ“ [{i}/{len(districts)}] {sido} {sigungu}")

        # skip_existing ì˜µì…˜ì´ Trueë©´ ê¸°ì¡´ ë°ì´í„° í™•ì¸
        if skip_existing and not force_update:
            with DatabaseManager() as db:
                existing_count = db.get_region_data_count(sido, sigungu)
                if existing_count > 0:
                    logger.info(f"â­ï¸  ì´ë¯¸ ìˆ˜ì§‘ë¨: {existing_count:,} ê±´ (ìŠ¤í‚µ)")
                    skip_count += 1
                    total_records += existing_count
                    continue

        # ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        success, count, time_stats = await collect_one_district(
            sido, sigungu, force_update
        )

        # ì‹œê°„ í†µê³„ ìˆ˜ì§‘
        if time_stats["total"] > 0:
            all_time_stats.append(time_stats)
            district_times.append((sigungu, time_stats["total"]))

        if success:
            success_count += 1
            total_records += count
        else:
            if count > 0:  # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì–´ì„œ ìŠ¤í‚µëœ ê²½ìš°
                skip_count += 1
                total_records += count
            else:  # ì‹¤íŒ¨í•œ ê²½ìš°
                fail_count += 1

        # ì§„í–‰ë¥  ì¶œë ¥
        progress = (i / len(districts)) * 100
        logger.info(f"\nğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({i}/{len(districts)})")

    # ============================================================
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    # ============================================================
    end_time = datetime.now()
    duration = end_time - start_time

    logger.info(f"\n\n{'='*60}")
    logger.info(f"ğŸ‰ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"{'='*60}")
    logger.info(f"ì´ ì²˜ë¦¬ êµ¬: {len(districts)} ê°œ")
    logger.info(f"âœ… ì„±ê³µ: {success_count} ê°œ")
    logger.info(f"â­ï¸  ìŠ¤í‚µ: {skip_count} ê°œ")
    logger.info(f"âŒ ì‹¤íŒ¨: {fail_count} ê°œ")
    logger.info(f"ğŸ“¦ ì´ ë ˆì½”ë“œ: {total_records:,} ê±´")
    logger.info(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {duration}")
    logger.info(f"ì¢…ë£Œ ì‹œê°: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{'='*60}\n")

    # ============================================================
    # ì‹œê°„ í†µê³„ ë¶„ì„
    # ============================================================
    if all_time_stats:
        logger.info(f"\nğŸ“Š ì‹œê°„ í†µê³„ ë¶„ì„")
        logger.info(f"{'='*60}")

        # ë‹¨ê³„ë³„ í‰ê·  ì‹œê°„ ê³„ì‚°
        avg_collect = sum(s["collect"] for s in all_time_stats) / len(all_time_stats)
        avg_preprocess = sum(s["preprocess"] for s in all_time_stats) / len(
            all_time_stats
        )
        avg_db_save = sum(s["db_save"] for s in all_time_stats) / len(all_time_stats)
        avg_total = sum(s["total"] for s in all_time_stats) / len(all_time_stats)

        # ë‹¨ê³„ë³„ ìµœì†Œ/ìµœëŒ€ ì‹œê°„
        min_collect = min(s["collect"] for s in all_time_stats)
        max_collect = max(s["collect"] for s in all_time_stats)
        min_preprocess = min(s["preprocess"] for s in all_time_stats)
        max_preprocess = max(s["preprocess"] for s in all_time_stats)
        min_db_save = min(s["db_save"] for s in all_time_stats)
        max_db_save = max(s["db_save"] for s in all_time_stats)

        logger.info(f"\n[ë‹¨ê³„ë³„ í‰ê·  ì†Œìš” ì‹œê°„]")
        logger.info(
            f"  1. ë°ì´í„° ìˆ˜ì§‘:  {avg_collect:>6.2f}ì´ˆ (ìµœì†Œ: {min_collect:.2f}ì´ˆ, ìµœëŒ€: {max_collect:.2f}ì´ˆ)"
        )
        logger.info(
            f"  2. ë°ì´í„° ì „ì²˜ë¦¬: {avg_preprocess:>6.2f}ì´ˆ (ìµœì†Œ: {min_preprocess:.2f}ì´ˆ, ìµœëŒ€: {max_preprocess:.2f}ì´ˆ)"
        )
        logger.info(
            f"  3. DB ì €ì¥:     {avg_db_save:>6.2f}ì´ˆ (ìµœì†Œ: {min_db_save:.2f}ì´ˆ, ìµœëŒ€: {max_db_save:.2f}ì´ˆ)"
        )
        logger.info(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        logger.info(f"  ì´ í‰ê· :        {avg_total:>6.2f}ì´ˆ")

        # êµ¬ë³„ ì „ì²´ ì‹œê°„ ê³„ì‚°
        total_collect = sum(s["collect"] for s in all_time_stats)
        total_preprocess = sum(s["preprocess"] for s in all_time_stats)
        total_db_save = sum(s["db_save"] for s in all_time_stats)

        logger.info(f"\n[ë‹¨ê³„ë³„ ì´ ì†Œìš” ì‹œê°„]")
        logger.info(
            f"  1. ë°ì´í„° ìˆ˜ì§‘:  {total_collect:>7.2f}ì´ˆ ({total_collect/60:>5.1f}ë¶„)"
        )
        logger.info(
            f"  2. ë°ì´í„° ì „ì²˜ë¦¬: {total_preprocess:>7.2f}ì´ˆ ({total_preprocess/60:>5.1f}ë¶„)"
        )
        logger.info(
            f"  3. DB ì €ì¥:     {total_db_save:>7.2f}ì´ˆ ({total_db_save/60:>5.1f}ë¶„)"
        )

        # ë³‘ëª© êµ¬ê°„ ë¶„ì„
        logger.info(f"\n[ë³‘ëª© êµ¬ê°„ ë¶„ì„]")
        total_time = total_collect + total_preprocess + total_db_save
        if total_time > 0:
            collect_pct = (total_collect / total_time) * 100
            preprocess_pct = (total_preprocess / total_time) * 100
            db_save_pct = (total_db_save / total_time) * 100

            logger.info(
                f"  ë°ì´í„° ìˆ˜ì§‘:  {collect_pct:>5.1f}% {'â–“' * int(collect_pct/5)}"
            )
            logger.info(
                f"  ë°ì´í„° ì „ì²˜ë¦¬: {preprocess_pct:>5.1f}% {'â–“' * int(preprocess_pct/5)}"
            )
            logger.info(
                f"  DB ì €ì¥:     {db_save_pct:>5.1f}% {'â–“' * int(db_save_pct/5)}"
            )

        # ê°€ì¥ ëŠë¦° êµ¬ Top 5
        if len(district_times) > 0:
            logger.info(f"\n[ì²˜ë¦¬ ì‹œê°„ì´ ê¸´ êµ¬ Top 5]")
            sorted_times = sorted(district_times, key=lambda x: x[1], reverse=True)[:5]
            for rank, (district, time) in enumerate(sorted_times, 1):
                logger.info(
                    f"  {rank}. {district:<10} {time:>6.2f}ì´ˆ ({time/60:>4.1f}ë¶„)"
                )

        logger.info(f"{'='*60}\n")
    else:
        logger.warning("ì‹œê°„ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # DB ìµœì¢… í†µê³„ ì¡°íšŒ
    try:
        with DatabaseManager() as db:
            stats = db.get_stats()
            logger.info(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ í†µê³„")
            logger.info(f"{'='*60}")
            for key, value in stats.items():
                logger.info(f"{key}: {value:,}")
            logger.info(f"{'='*60}\n")
    except Exception as e:
        logger.warning(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")


# ============================================================
# CLI ì¸í„°í˜ì´ìŠ¤
# ============================================================


async def list_sido():
    """ì „êµ­ ì‹œë„ ëª©ë¡ ì¡°íšŒ (--list-sido ì˜µì…˜)"""
    logger.info("\nğŸ“‹ ì „êµ­ ì‹œë„ ëª©ë¡\n")
    logger.info("=" * 60)

    items = await get_all_sido_list()

    logger.info(f"\n{'ì½”ë“œ':<6} {'ì‹œë„ëª…':<15}")
    logger.info("-" * 60)
    for item in items:
        code = item.get("ctprvnCd", "")
        name = item.get("ctprvnNm", "")
        logger.info(f"{code:<6} {name:<15}")

    logger.info("=" * 60)
    logger.info(f"ì´ {len(items)} ê°œ ì‹œë„")
    logger.info("\nì‚¬ìš© ì˜ˆì‹œ:")
    logger.info("  python batch_collect.py --sido ì„œìš¸íŠ¹ë³„ì‹œ")
    logger.info("  python batch_collect.py --sido ë¶€ì‚°ê´‘ì—­ì‹œ")


async def list_districts(sido: str):
    """íŠ¹ì • ì‹œë„ì˜ ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ (--list-districts ì˜µì…˜)"""
    logger.info(f"\nğŸ“‹ {sido} ì‹œêµ°êµ¬ ëª©ë¡\n")
    logger.info("=" * 60)

    districts = await get_districts_from_api(sido)

    logger.info(f"\në²ˆí˜¸  ì‹œêµ°êµ¬ëª…")
    logger.info("-" * 60)
    for i, name in enumerate(districts, 1):
        logger.info(f"{i:>3}.  {name}")

    logger.info("=" * 60)
    logger.info(f"ì´ {len(districts)} ê°œ ì‹œêµ°êµ¬")
    logger.info("\nì‚¬ìš© ì˜ˆì‹œ:")
    logger.info(f"  python batch_collect.py --sido {sido}")
    logger.info(f"  python batch_collect.py --sido {sido} --districts ê°•ë‚¨êµ¬ ê°•ë™êµ¬")


def main():
    """CLI ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ìƒê°€ì—…ì†Œ ë°ì´í„° ë°°ì¹˜ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (API ê¸°ë°˜ ì§€ì—­ ëª©ë¡ ìë™ ì¡°íšŒ)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì„œìš¸ì‹œ ì „ì²´ ìë™ ìˆ˜ì§‘ (APIë¡œ êµ¬ ëª©ë¡ ì¡°íšŒ)
  python batch_collect.py

  # ë¶€ì‚°ì‹œ ì „ì²´ ìë™ ìˆ˜ì§‘
  python batch_collect.py --sido ë¶€ì‚°ê´‘ì—­ì‹œ

  # ì „êµ­ ì‹œë„ ëª©ë¡ ì¡°íšŒ
  python batch_collect.py --list-sido

  # ì„œìš¸ì‹œ êµ¬ ëª©ë¡ ì¡°íšŒ
  python batch_collect.py --list-districts --sido ì„œìš¸íŠ¹ë³„ì‹œ

  # íŠ¹ì • êµ¬ë§Œ ìˆ˜ì§‘
  python batch_collect.py --districts ê°•ë‚¨êµ¬ ê°•ë™êµ¬ ì†¡íŒŒêµ¬

  # ê¸°ì¡´ ë°ì´í„° ë®ì–´ì“°ê¸°
  python batch_collect.py --force

  # ì´ë¯¸ ìˆ˜ì§‘ëœ êµ¬ ìŠ¤í‚µ
  python batch_collect.py --skip-existing
        """,
    )

    parser.add_argument(
        "--sido", type=str, default="ì„œìš¸íŠ¹ë³„ì‹œ", help="ì‹œë„ëª… (ê¸°ë³¸ê°’: ì„œìš¸íŠ¹ë³„ì‹œ)"
    )

    parser.add_argument(
        "--districts", nargs="+", help="ìˆ˜ì§‘í•  ì‹œêµ°êµ¬ ëª©ë¡ (ë¯¸ì§€ì • ì‹œ APIë¡œ ìë™ ì¡°íšŒ)"
    )

    parser.add_argument(
        "--force", action="store_true", help="ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ì¬ìˆ˜ì§‘"
    )

    parser.add_argument(
        "--skip-existing", action="store_true", help="ì´ë¯¸ DBì— ìˆëŠ” ì§€ì—­ì€ ìŠ¤í‚µ"
    )

    parser.add_argument(
        "--list-sido", action="store_true", help="ì „êµ­ ì‹œë„ ëª©ë¡ ì¡°íšŒ í›„ ì¢…ë£Œ"
    )

    parser.add_argument(
        "--list-districts",
        action="store_true",
        help="íŠ¹ì • ì‹œë„ì˜ ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ í›„ ì¢…ë£Œ",
    )

    args = parser.parse_args()

    # --list-sido ì˜µì…˜: ì‹œë„ ëª©ë¡ ì¡°íšŒ í›„ ì¢…ë£Œ
    if args.list_sido:
        asyncio.run(list_sido())
        return

    # --list-districts ì˜µì…˜: ì‹œêµ°êµ¬ ëª©ë¡ ì¡°íšŒ í›„ ì¢…ë£Œ
    if args.list_districts:
        asyncio.run(list_districts(args.sido))
        return

    # ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰
    asyncio.run(
        batch_collect(
            sido=args.sido,
            districts=args.districts,
            force_update=args.force,
            skip_existing=args.skip_existing,
        )
    )


if __name__ == "__main__":
    main()
